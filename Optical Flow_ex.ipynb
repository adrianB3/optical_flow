{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical flow tracks objects by looking at where the same points have moved from one image frame to the next.\n",
    "# Let's load in a few example frames of a pacman-like face moving to the right and down and see how optical flow \n",
    "# finds motion vectors that describe the motion of the face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as mpimg  # for reading in images\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in np.sort(os.listdir(folder)):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = load_images_from_folder('images/')\n",
    "np.shape(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB) for i in range(0,np.shape(frames)[0])]\n",
    "np.shape(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,a = plt.subplots(1, np.shape(frames)[0], figsize=(20,20))\n",
    "for i in range (0,np.shape(frames)[0]):\n",
    "    a[i].set_title('frame '+ str(i))\n",
    "    a[i].imshow(frames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all frames to grayscale\n",
    "# gray = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_1=gray[0]\n",
    "gray_2=gray[1]\n",
    "gray_3=gray[2]\n",
    "gray_4=gray[3]\n",
    "gray_5=gray[4]\n",
    "gray_6=gray[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Points to Track\n",
    "# Before optical flow can work, we have to give it a set of keypoints to track between two image frames!\n",
    "\n",
    "# In the below example, we use a Shi-Tomasi corner detector, which uses the same process as a Harris corner detector \n",
    "# to find patterns of intensity that make up a \"corner\" in an image, only it adds an additional parameter that\n",
    "# helps select the most prominent corners. You can read more about this detection algorithm in the documentation.\n",
    "\n",
    "# Alternatively, the Harris detector could be used to find feature points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 1,\n",
    "                       qualityLevel = 0.2,\n",
    "                       minDistance = 150,\n",
    "                       blockSize = 5 )\n",
    "\n",
    "\n",
    "# Take first frame and find corner points in it\n",
    "pts_1 = cv2.goodFeaturesToTrack(gray_1, mask = None, **feature_params)\n",
    "\n",
    "# display the detected points\n",
    "plt.imshow(frames[0])\n",
    "for p in pts_1:\n",
    "    # plot x and y detected points\n",
    "    plt.plot(p[0][0], p[0][1], 'r.', markersize=15)\n",
    "\n",
    "# print out the x-y locations of the detected points\n",
    "print(pts_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Optical Flow\n",
    "\n",
    "# Once we've detected keypoints on our initial image of interest, we can calculate\n",
    "#the optical flow between this image frame (frame 1) and the next frame (frame 2),\n",
    "# using OpenCV's calcOpticalFlowPyrLK which is documented, here. It takes in an initial image frame,\n",
    "# the next image, and the first set of points, and it returns the detected points in the next frame\n",
    "# and a value that indicates how good matches are between points from one frame to the next.\n",
    "\n",
    "# The parameters also include a window size and maxLevels that indicate the size of a window and mnumber \n",
    "# of levels that will be used to scale the given images using pyramid scaling; this version peforms an iterative\n",
    "# search for matching points and this matching criteria is reflected in the last parameter \n",
    "# (you may need to change these values if you are working with a different image,\n",
    "#but these should work for the provided example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (1,1),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Take first frame and find corner points in it\n",
    "pts_2 = cv2.goodFeaturesToTrack(gray_2, mask = None, **feature_params)\n",
    "\n",
    "plt.imshow(frames[1])\n",
    "for p in pts_2:\n",
    "    # plot x and y detected points\n",
    "    plt.plot(p[0][0], p[0][1], 'r.', markersize=15)\n",
    "\n",
    "# print out the x-y locations of the detected points\n",
    "print(pts_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate optical flow between first and second frame\n",
    "pts_2, match, err = cv2.calcOpticalFlowPyrLK(gray_1, gray_2, pts_1,None, **lk_params)\n",
    "\n",
    "# Select good matching points between the two image frames\n",
    "good_new = pts_2[match==1]\n",
    "good_old = pts_1[match==1]\n",
    "print(pts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's display the resulting motion vectors! You should see the first image with motion vectors drawn\n",
    "# on it that indicate the direction of motion from the first frame to the next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(frames[1])\n",
    "\n",
    "# draw the lines between the matching points (these lines indicate motion vectors)\n",
    "for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "    a,b = new.ravel()\n",
    "    c,d = old.ravel()\n",
    "    a = int(a)\n",
    "    b = int(b)\n",
    "    c = int(c)\n",
    "    d = int(d)\n",
    "    # draw points on the mask image\n",
    "    mask = cv2.circle(mask,(a,b),5,(200),-1)\n",
    "    # draw motion vector as lines on the mask image\n",
    "    mask = cv2.line(mask, (a,b),(c,d), (200), 3)\n",
    "    # add the line image and second frame together\n",
    "\n",
    "composite_im = np.copy(frames[1])\n",
    "composite_im[mask!=0] = [0]\n",
    "\n",
    "plt.imshow(composite_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Perform optical flow between image frames 2 and 3\n",
    "\n",
    "# Now take the second frame and find corner points in it just like first frame\n",
    "pts_2 = cv2.goodFeaturesToTrack(gray_2, mask = None, **feature_params)\n",
    "\n",
    "# calculate second and third frame\n",
    "pts_3, match, err = cv2.calcOpticalFlowPyrLK(gray_2, gray_3, pts_2, None, **lk_params)\n",
    "\n",
    "# good matching points between the two frames\n",
    "good_new = pts_3[match==1]\n",
    "good_old = pts_2[match==1]\n",
    "\n",
    "# mask image for drawing (u,v) vectors on top of the third frame\n",
    "mask = np.zeros_like(frames[2])\n",
    "\n",
    "# this will draw lines between the matching points (lines indicate motion)\n",
    "for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "    a,b = new.ravel()\n",
    "    c,d = old.ravel()\n",
    "    a = int(a)\n",
    "    b = int(b)\n",
    "    c = int(c)\n",
    "    d = int(d)\n",
    "    # draw points on the mask image\n",
    "    mask = cv2.circle(mask,(a,b),5,(200),-1)\n",
    "    # draw motion vector as lines on the mask image\n",
    "    mask = cv2.line(mask, (a,b),(c,d), (200), 3)\n",
    "    # add the line image and second frame together\n",
    "\n",
    "composite_im = np.copy(frames[2])\n",
    "composite_im[mask!=0] = [0]\n",
    "\n",
    "plt.imshow(composite_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework\n",
    "\n",
    "(Mandatory)\n",
    "- Apply lk optical flow on all frames\n",
    "- Draw the full feature tracking history over all frames\n",
    "- Use different sequence of images\n",
    "\n",
    "(Optional)\n",
    "- Use dense optical flow (Farneback) on the same images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
